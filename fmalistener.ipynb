{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, numpy as np\n",
    "import numpy as np\n",
    "from mnist.loader import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os, json, math, hashlib, random, pickle\n",
    "import h5py\n",
    "import librosa\n",
    "import umap\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from pathlib2 import Path\n",
    "\n",
    "#import torch.nn.functional as F\n",
    "#from torch import nn\n",
    "#import torch\n",
    "\n",
    "import math\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "SEED=88\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "#torch.manual_seed(88)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature functions (split into beat tokens)\n",
    "- chroma\n",
    "- tonnetz\n",
    "- mfcc data\n",
    "- mel data\n",
    "- some representation of the tempogram (1d conv, perhaps with kernel 7, size 16)\n",
    "- rolloff: brightness\n",
    "- flatness: noisiness\n",
    "(note to keep dimensions small.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP=512\n",
    "SR=44100 \n",
    "def tokens_from_mp3(path):\n",
    "    #y: signal\n",
    "    y, sr = librosa.load(path, sr=SR, mono=True)\n",
    "    y = librosa.util.normalize(y)\n",
    "    y_h, y_p = librosa.effects.hpss(y) #percussive splitting\n",
    "\n",
    "    #compute beat markers via onset graph\n",
    "    onsets = librosa.onset.onset_strength(y=y_p, sr=SR, hop_length=STEP)\n",
    "    tempo, beat_frames = librosa.beat.beat_track(onset_envelope=onsets, sr=SR)\n",
    "    if len(beat_frames)<2:\n",
    "        return None\n",
    "\n",
    "    chroma = librosa.feature.chroma_cqt(y=y_h, sr=SR, hop_length = STEP, bins_per_octave=36)\n",
    "    tonnetz = librosa.feature.tonnetz(chroma=chroma)\n",
    "    \n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=SR, n_mels=96, hop_length=STEP)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=20)\n",
    "    mfcc_d1 = librosa.feature.delta(mfcc, order=1)\n",
    "    \n",
    "    tempogram = librosa.feature.tempogram(onset_envelope=onsets, sr=sr, hop_length=STEP)\n",
    "    rms = librosa.feature.rms(y=y, frame_length=2048, hop_length=STEP)\n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=SR, hop_length=STEP)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=SR, hop_length=STEP)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y, hop_length=STEP)\n",
    "    \n",
    "    def sync(feat, agg=np.mean):\n",
    "        return librosa.util.sync(feat, beat_frames, aggregate=agg)\n",
    "    \n",
    "    beats = {\n",
    "        \"chroma\": sync(chroma, np.mean),                    # (12, n_beats)\n",
    "        \"tonnetz\": sync(tonnetz, np.mean),                  # (6, n_beats)\n",
    "        \"mel_mean\": sync(mel_db, np.mean),                  # (96, n_beats)\n",
    "        \"mel_max\": sync(mel_db, np.max),                    # (96, n_beats)\n",
    "        \"mfcc\": sync(mfcc, np.mean),                        # (20, n_beats)\n",
    "        \"mfcc_d1\": sync(mfcc_d1, np.mean),                  # (20, n_beats)\n",
    "        \"tempogram_mean\": sync(tempogram, np.mean),         # (128, n_beats). try to conv1d this later\n",
    "        \"rms\": sync(rms, np.mean),                          # (1, n_beats)\n",
    "        \"centroid\": sync(centroid, np.mean),                # (1, n_beats)\n",
    "        \"rolloff\": sync(rolloff, np.mean),                  # (1, n_beats)\n",
    "        \"flatness\": sync(flatness, np.mean),                # (1, n_beats)\n",
    "    }\n",
    "    \n",
    "    tg = beats[\"tempogram_mean\"]\n",
    "    beats[\"temp_peak_bpms\"] = tg.argmax(axis=0, keepdims=True)\n",
    "    \n",
    "    n_beats = beats[\"chroma\"].shape[1]\n",
    "    pos = np.arange(n_beats, dtype=np.float32)[None, :]\n",
    "    beats[\"index\"] = pos\n",
    "    \n",
    "    feat_list = [\n",
    "        beats[\"chroma\"], beats[\"tonnetz\"], beats[\"mel_mean\"], beats[\"mfcc\"], beats[\"mfcc_d1\"], beats[\"tempogram_mean\"], beats[\"rms\"], beats[\"centroid\"], beats[\"rolloff\"], beats[\"flatness\"]\n",
    "    ]\n",
    "    X = np.concatenate(feat_list, axis=0).T.astype(np.float32) \n",
    "    return X #(12+6+96+20+20+T+1+1+1+1, n_beats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ROOT = Path(\"./fma_small\")\n",
    "CSV = Path(\"./cache/fma_small.csv\")\n",
    "CACHE = Path(\"./cache/beat_tokens\")\n",
    "\n",
    "def paths(root_path):\n",
    "    return sorted(root_path.rglob(\"*.mp3\"))\n",
    "all_paths = paths(ROOT)\n",
    "\n",
    "def relative_cache_path(audio_path, audio_dir, cache_dir):\n",
    "    relative = audio_path.relative_to(audio_dir)\n",
    "    return (cache_dir/relative.parent/(relative.stem+\".npz\"))\n",
    "\n",
    "def process_one_mp3(path, audio_dir, cache_dir):\n",
    "    try:\n",
    "        tokens = tokens_from_mp3(str(path))\n",
    "        if tokens is None or len(tokens)<2 or tokens.shape[0]<2:\n",
    "            return None\n",
    "        \n",
    "        npz_path = relative_cache_path(path, audio_dir, cache_dir)\n",
    "        npz_path.parent.mkdir(parents=True, exist_ok=True) #file not found errors\n",
    "        \n",
    "        np.savez_compressed(npz_path, tokens=tokens.astype(np.float32))\n",
    "        \n",
    "        row = dict(\n",
    "            audio=str(path),\n",
    "            npz_path=str(npz_path),\n",
    "            npz=str(npz_path.name),\n",
    "            n_beats=int(tokens.shape[0]),\n",
    "            dim = int(tokens.shape[1]),\n",
    "        )\n",
    "        return row\n",
    "    except Exception as e:\n",
    "        print(f\"failed to process mp3 at {path}/{e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 490/7999 [22:56<5:42:39,  2.74s/it][src/libmpg123/layer3.c:INT123_do_layer3():1844] error: dequantization failed!\n",
      " 11%|█▏        | 901/7999 [41:52<5:16:32,  2.68s/it][src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      " 15%|█▍        | 1181/7999 [54:25<5:01:44,  2.66s/it][src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      " 28%|██▊       | 2264/7999 [2:34:06<4:36:20,  2.89s/it]   [src/libmpg123/layer3.c:INT123_do_layer3():1776] error: part2_3_length (3360) too large for available bit count (3240)\n",
      " 28%|██▊       | 2266/7999 [2:34:12<4:33:33,  2.86s/it][src/libmpg123/layer3.c:INT123_do_layer3():1776] error: part2_3_length (3328) too large for available bit count (3240)\n",
      " 55%|█████▌    | 4422/7999 [6:09:13<3:38:27,  3.66s/it]   Note: Illegal Audio-MPEG-Header 0x00000000 at offset 33361.\n",
      "Note: Trying to resync...\n",
      "/var/folders/v7/96pnb7v52cn4swxgq3j09dbm0000gq/T/ipykernel_11342/3423988924.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(path, sr=SR, mono=True)\n",
      "/Users/user/Desktop/coding comps/transition/venv/lib/python3.13/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "/Users/user/Desktop/coding comps/transition/venv/lib/python3.13/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=558\n",
      "  warnings.warn(\n",
      " 55%|█████▌    | 4423/7999 [6:09:13<2:40:07,  2.69s/it]Note: Illegal Audio-MPEG-Header 0x00000000 at offset 22401.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "/Users/user/Desktop/coding comps/transition/venv/lib/python3.13/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=720\n",
      "  warnings.warn(\n",
      "/Users/user/Desktop/coding comps/transition/venv/lib/python3.13/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=360\n",
      "  warnings.warn(\n",
      "/Users/user/Desktop/coding comps/transition/venv/lib/python3.13/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=180\n",
      "  warnings.warn(\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 63168.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1349] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "/Users/user/Desktop/coding comps/transition/venv/lib/python3.13/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=531\n",
      "  warnings.warn(\n",
      " 56%|█████▌    | 4469/7999 [6:19:01<25:54:38, 26.42s/it]  [src/libmpg123/parse.c:do_readahead():1083] warning: Cannot read next header, a one-frame stream? Duh...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to process mp3 at fma_small/099/099134.mp3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 4902/7999 [7:09:48<16:14:03, 18.87s/it]  [src/libmpg123/parse.c:do_readahead():1083] warning: Cannot read next header, a one-frame stream? Duh...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to process mp3 at fma_small/108/108925.mp3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 6964/7999 [8:45:20<48:39,  2.82s/it]   [src/libmpg123/parse.c:do_readahead():1083] warning: Cannot read next header, a one-frame stream? Duh...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to process mp3 at fma_small/133/133297.mp3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7999/7999 [9:34:16<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7995\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>npz_path</th>\n",
       "      <th>npz</th>\n",
       "      <th>n_beats</th>\n",
       "      <th>dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fma_small/000/000002.mp3</td>\n",
       "      <td>cache/beat_tokens/000/000002.npz</td>\n",
       "      <td>000002.npz</td>\n",
       "      <td>82</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fma_small/000/000005.mp3</td>\n",
       "      <td>cache/beat_tokens/000/000005.npz</td>\n",
       "      <td>000005.npz</td>\n",
       "      <td>51</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fma_small/000/000010.mp3</td>\n",
       "      <td>cache/beat_tokens/000/000010.npz</td>\n",
       "      <td>000010.npz</td>\n",
       "      <td>56</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      audio                          npz_path         npz  \\\n",
       "0  fma_small/000/000002.mp3  cache/beat_tokens/000/000002.npz  000002.npz   \n",
       "1  fma_small/000/000005.mp3  cache/beat_tokens/000/000005.npz  000005.npz   \n",
       "2  fma_small/000/000010.mp3  cache/beat_tokens/000/000010.npz  000010.npz   \n",
       "\n",
       "   n_beats  dim  \n",
       "0       82  542  \n",
       "1       51  542  \n",
       "2       56  542  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def create_manifest(paths, root_path, cache_dir, batch_size=None):\n",
    "    rows=[]\n",
    "    will_iterate = paths if batch_size is None else paths[:batch_size]\n",
    "    for path in tqdm.tqdm(will_iterate):\n",
    "        temp = process_one_mp3(path, root_path, cache_dir)\n",
    "        if temp is not None:\n",
    "            rows.append(temp)\n",
    "    \n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"audio\"]).reset_index(drop=True) #clean\n",
    "    return df  \n",
    "\n",
    "manifest_df = create_manifest(all_paths, ROOT, CACHE)\n",
    "print(f\"Processed {len(manifest_df)}\")\n",
    "manifest_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location: /Users/user/Desktop/coding comps/transition/cache/fma_small.csv\n",
      "tokens w size size 542\n",
      "median file: 61.0\n"
     ]
    }
   ],
   "source": [
    "manifest_df.to_csv(CSV)\n",
    "print(\"location:\", CSV.resolve())\n",
    "\n",
    "if len(manifest_df):\n",
    "    print(f\"tokens w size size {manifest_df.iloc[0][\"dim\"]}\")\n",
    "    print(f\"median file: {manifest_df[\"n_beats\"].median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then split into test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>npz_path</th>\n",
       "      <th>npz</th>\n",
       "      <th>n_beats</th>\n",
       "      <th>dim</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fma_small/000/000002.mp3</td>\n",
       "      <td>cache/beat_tokens/000/000002.npz</td>\n",
       "      <td>000002.npz</td>\n",
       "      <td>82</td>\n",
       "      <td>542</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fma_small/000/000005.mp3</td>\n",
       "      <td>cache/beat_tokens/000/000005.npz</td>\n",
       "      <td>000005.npz</td>\n",
       "      <td>51</td>\n",
       "      <td>542</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fma_small/000/000010.mp3</td>\n",
       "      <td>cache/beat_tokens/000/000010.npz</td>\n",
       "      <td>000010.npz</td>\n",
       "      <td>56</td>\n",
       "      <td>542</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      audio                          npz_path         npz  \\\n",
       "0  fma_small/000/000002.mp3  cache/beat_tokens/000/000002.npz  000002.npz   \n",
       "1  fma_small/000/000005.mp3  cache/beat_tokens/000/000005.npz  000005.npz   \n",
       "2  fma_small/000/000010.mp3  cache/beat_tokens/000/000010.npz  000010.npz   \n",
       "\n",
       "   n_beats  dim  split  \n",
       "0       82  542  train  \n",
       "1       51  542    val  \n",
       "2       56  542  train  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(tokens_df, train=0.8, val=0.1):\n",
    "    copy = tokens_df.sort_values(\"npz_path\").reset_index(drop=True).copy()\n",
    "    if len(copy)==0: return copy\n",
    "    idx = np.arange(len(copy))\n",
    "    \n",
    "    rng = np.random.RandomState(SEED)\n",
    "    rng.shuffle(idx)\n",
    "    \n",
    "    split = np.array([\"test\"] * len(copy), dtype=object) \n",
    "    split[idx[: int(train * len(copy))]] = \"train\"\n",
    "    split[idx[int(train * len(copy)) : int((train + val) * len(copy))]] = \"val\"\n",
    "    \n",
    "    copy[\"split\"] = split\n",
    "    return copy\n",
    "\n",
    "    \n",
    "    \n",
    "manifest_df = split(manifest_df)\n",
    "manifest_df.to_csv(CSV)\n",
    "\n",
    "manifest_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
